services:
  video-api-wan:
    build:
      context: ./video_api
      dockerfile: Dockerfile.wan22
    profiles: ["wan"]
    volumes:
      - model_cache:/app/model_cache
    environment:
      - VIDEO_MODEL=wan2.2-14b
      - HF_HOME=/app/model_cache
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; r=urllib.request.urlopen('http://localhost:8000/health'); import json; d=json.loads(r.read()); exit(0 if d['status']=='ready' else 1)"]
      interval: 30s
      timeout: 10s
      retries: 30
      start_period: 600s
    restart: unless-stopped

  video-api-ltx:
    image: compunct/video-api:ltx2
    build:
      context: ./video_api
      dockerfile: Dockerfile.ltx2
    profiles: ["ltx"]
    volumes:
      - model_cache:/app/model_cache
    environment:
      - VIDEO_MODEL=ltx2-distilled
      - HF_HOME=/app/model_cache
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    env_file:
      - .env
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; r=urllib.request.urlopen('http://localhost:8000/health'); import json; d=json.loads(r.read()); exit(0 if d['status']=='ready' else 1)"]
      interval: 30s
      timeout: 10s
      retries: 30
      start_period: 600s
    restart: unless-stopped

volumes:
  model_cache:
